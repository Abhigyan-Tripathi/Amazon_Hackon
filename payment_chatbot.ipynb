{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4836bc78-6a94-4e13-bc0c-23dfb6cce0d8",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8342373-5bf9-46b2-900f-ee40e9845ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "from flask import Flask, request, jsonify\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f0727-8e7a-4aa2-b6b5-a1d2b92f446b",
   "metadata": {},
   "source": [
    "## Connect to postgres server and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae4d8d7-dcb3-45e6-87dc-892e699a064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:postgres123@localhost:5432/postgres')\n",
    "customer_logs = pd.read_sql('SELECT * FROM customer_service_logs', engine)\n",
    "payment_data = pd.read_sql('SELECT * FROM payments', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6702d-6954-49c4-b45a-791ffbdf29b7",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7d2405-7e51-403f-907a-6d08b80182c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abhigyantripathi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/abhigyantripathi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import ssl\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "customer_logs['processed_text'] = customer_logs['query'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea0ac7-aff2-414d-8c0d-0494c3cd6b6c",
   "metadata": {},
   "source": [
    "## Creating and Training the sentiment analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0875825c-c18f-46ba-8fb2-ea6e0fb59211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/abhigyantripathi/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m X_test_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mscore(X_test_tfidf,\u001b[38;5;250m \u001b[39my_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 'positive'"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline('sentiment-analysis')\n",
    "\n",
    "# Example training data\n",
    "sentiment_data = customer_logs[['processed_text', 'sentiment']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentiment_data['processed_text'], sentiment_data['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"Model accuracy: {model.score(X_test_tfidf, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f76cb-cf8a-478b-a8c3-a99b0218b1df",
   "metadata": {},
   "source": [
    "## Building the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803ad96b-d5d4-4761-aac6-9dce8d86c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query):\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    sentiment = sentiment_pipeline(preprocessed_query)[0]['label']\n",
    "\n",
    "    if 'payment' in preprocessed_query:\n",
    "        response = handle_payment_query(preprocessed_query)\n",
    "    else:\n",
    "        response = \"I'm sorry, I can only help with payment-related queries.\"\n",
    "\n",
    "    return response, sentiment\n",
    "\n",
    "def handle_payment_query(query):\n",
    "    if \"status\" in query:\n",
    "        payment_id = extract_payment_id(query)\n",
    "        payment_status = get_payment_status(payment_id)\n",
    "        return f\"Your payment status is: {payment_status}\"\n",
    "    elif \"issue\" in query:\n",
    "        return \"There seems to be an issue with your payment. Please contact support.\"\n",
    "    else:\n",
    "        return \"Can you please provide more details about your payment query?\"\n",
    "\n",
    "def extract_payment_id(query):\n",
    "    # Placeholder function to extract payment ID from the query\n",
    "    return int(query.split()[-1])\n",
    "\n",
    "def get_payment_status(payment_id):\n",
    "    query = f\"SELECT status FROM payments WHERE payment_id = {payment_id}\"\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query)\n",
    "        payment_status = result.fetchone()[0]\n",
    "    return payment_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f5c62-9f60-4127-9ca1-472f87b66200",
   "metadata": {},
   "source": [
    "## Deploying the chatbot using flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a84ed0-1fe1-4b40-becf-682e59186f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/Users/abhigyantripathi/venv/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 311, in bind\n",
      "    super().bind(addr)\n",
      "  File \"_zmq.py\", line 898, in zmq.backend.cython._zmq.Socket.bind\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:55923')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhigyantripathi/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def query():\n",
    "    data = request.get_json()\n",
    "    query = data.get('query', '')\n",
    "    response, sentiment = handle_query(query)\n",
    "    return jsonify({'response': response, 'sentiment': sentiment})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6c942f-c554-480c-8355-ffd289643bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "##import requests\n",
    "\n",
    "##url = 'http://127.0.0.1:5001/query'\n",
    "##data = {'query': 'How do I make a payment?'}\n",
    "##response = requests.post(url, json=data)\n",
    "##print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9802054f-9e17-4c91-9060-8fee9be93c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The above code is an example of a request made to the chatbot server which will return the reuired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881999c6-21a4-461d-8a49-8dca532296fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
